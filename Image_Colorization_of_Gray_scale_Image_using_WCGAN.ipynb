{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 125589,
          "sourceType": "datasetVersion",
          "datasetId": 50512
        },
        {
          "sourceId": 4899433,
          "sourceType": "datasetVersion",
          "datasetId": 2788023
        }
      ],
      "dockerImageVersionId": 30302,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Image Colorization of Gray scale Image using WCGAN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/You2751/Colorization-of-gray-scale-images-using-WCGAN/blob/main/Image_Colorization_of_Gray_scale_Image_using_WCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-colorization:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F50512%2F125589%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240218%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240218T080127Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2d6243f2e6f39021e47f54208fde138b8bfecffcdc32000a5aa580a304404b49c3c1e734237b8b7a050549121373c5fbaba8d9d69bcbfbbe57fcc4b060ccaaa5611f24de6f214e2d5938912a2de127cb1bec3f18982f2ea48bbccbc341eb6344b9cc95d9480fe539c00838cf179307d7e0fb0ba8f081ad8fc37f6a342671d21fe99b89a088b67665b6a1809cf3bcf12aca16f6e968b08f70f85903f0a96c2ba6d3f1292acdafbe889c446037ee1418d2a5da8f30f0c860d182113437fce42f46bb803622eae4be21e3c9203413e7471451b7b8f07de8f81e6cd7aa96704f07a91fd22f9051d03d16b0acb4848f07455c4cf802360df96adcddb2ac99683e2a3d,pretrained-resunet-patchgan:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2788023%2F4899433%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240218%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240218T080127Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0d5a3e9ae48d8c0fa8dda73fd463062eabb341744034911bd3d5eaa155fab744671c9c683431f3bf8bafe40209e20f7ac154f69bf9137fb590c5027fa614d927bb07afb55de2fe488caa3e41df280f178aa4d92807db4c31f149bcbd9ea25acc1b1ba09b558bf17708026f62fbc31d40fbb61e303fb14a9233af26a94ca0efe14118b31d8a160031c5c3896349c8a0ae06f3b1f83468466ba183d4f357816601ce040de129ba559af4808d79376fcb014ed6fc0b8b0a1319643a9673b584ad932024ea9044b528c749142c4894587ab3ed9c32caf10d799af5aa3e1b92e3a5bb21d4232e01a8e52d0ea10e2d3e793d907a1e689d73a6d719e7d11a67180e5755'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "8mIJlupcPYJk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7JTmapBPYjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "!pip install pytorch-lightning --no-cache-dir"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:22:57.433869Z",
          "iopub.execute_input": "2023-12-15T20:22:57.434989Z",
          "iopub.status.idle": "2023-12-15T20:23:21.704025Z",
          "shell.execute_reply.started": "2023-12-15T20:22:57.434945Z",
          "shell.execute_reply": "2023-12-15T20:23:21.70272Z"
        },
        "trusted": true,
        "id": "WmaOK-xPPYJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from scipy.stats import entropy\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models.inception import inception_v3\n",
        "from torchsummary import summary\n",
        "\n",
        "# Set matplotlib style\n",
        "matplotlib.style.use('fivethirtyeight')\n",
        "\n",
        "# Ignore unnecessary warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:21.707143Z",
          "iopub.execute_input": "2023-12-15T20:23:21.707505Z",
          "iopub.status.idle": "2023-12-15T20:23:27.033777Z",
          "shell.execute_reply.started": "2023-12-15T20:23:21.70747Z",
          "shell.execute_reply": "2023-12-15T20:23:27.032593Z"
        },
        "trusted": true,
        "id": "miK4DKLHPYJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>II. Data Preparation</center></h1>\n"
      ],
      "metadata": {
        "id": "_ri-jiefPYJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_path = \"/kaggle/input/image-colorization/ab/ab/ab1.npy\"\n",
        "l_path = \"/kaggle/input/image-colorization/l/gray_scale.npy\"\n",
        "\n",
        "# Load data and create dataset\n",
        "L_df, ab_df = np.load(l_path)[:6000], np.load(ab_path)[:6000]\n",
        "dataset = (L_df, ab_df)\n",
        "\n",
        "# Perform garbage collection\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:27.035081Z",
          "iopub.execute_input": "2023-12-15T20:23:27.035739Z",
          "iopub.status.idle": "2023-12-15T20:23:48.050896Z",
          "shell.execute_reply.started": "2023-12-15T20:23:27.035703Z",
          "shell.execute_reply": "2023-12-15T20:23:48.049881Z"
        },
        "trusted": true,
        "id": "Lt5_JHkVPYJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>III. Data Exploration and Visualiaztion</center></h1>\n"
      ],
      "metadata": {
        "id": "bv1wiNvJPYJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lab_to_rgb(L, ab):\n",
        "    L = L * 100\n",
        "    ab = (ab - 0.5) * 128 * 2\n",
        "\n",
        "    # Move tensors to the same device before concatenation\n",
        "    L = L.to(ab.device)\n",
        "\n",
        "    Lab = torch.cat([L, ab], dim=2).cpu().numpy()\n",
        "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
        "    return np.stack(rgb_imgs, axis=0)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:48.053963Z",
          "iopub.execute_input": "2023-12-15T20:23:48.054389Z",
          "iopub.status.idle": "2023-12-15T20:23:48.063488Z",
          "shell.execute_reply.started": "2023-12-15T20:23:48.054346Z",
          "shell.execute_reply": "2023-12-15T20:23:48.062598Z"
        },
        "trusted": true,
        "id": "7vBRyHsSPYJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 30))\n",
        "\n",
        "for i in range(0, 15, 2):\n",
        "    # Grayscale subplot\n",
        "    grayscale_img = np.zeros((224, 224, 3))\n",
        "    grayscale_img[:, :, 0] = L_df[i]\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.title('Grayscale')\n",
        "    plt.imshow(lab2rgb(grayscale_img))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Colored subplot\n",
        "    colored_img = np.zeros((224, 224, 3))\n",
        "    colored_img[:, :, 0] = L_df[i]  # Grayscale channel\n",
        "    colored_img[:, :, 1:] = ab_df[i]  # Color channels\n",
        "    colored_img = colored_img.astype('uint8')\n",
        "    colored_img = cv2.cvtColor(colored_img, cv2.COLOR_LAB2RGB)\n",
        "    plt.subplot(4, 4, i + 2)\n",
        "    plt.title('Colored')\n",
        "    plt.imshow(colored_img)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:48.064678Z",
          "iopub.execute_input": "2023-12-15T20:23:48.064968Z",
          "iopub.status.idle": "2023-12-15T20:23:50.164443Z",
          "shell.execute_reply.started": "2023-12-15T20:23:48.064941Z",
          "shell.execute_reply": "2023-12-15T20:23:50.162994Z"
        },
        "trusted": true,
        "id": "xXn4TszhPYJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.166284Z",
          "iopub.execute_input": "2023-12-15T20:23:50.166805Z",
          "iopub.status.idle": "2023-12-15T20:23:50.347766Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.166758Z",
          "shell.execute_reply": "2023-12-15T20:23:50.346695Z"
        },
        "trusted": true,
        "id": "cK7zl3ztPYJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>III. Data Loader</center></h1>\n"
      ],
      "metadata": {
        "id": "Iq3dSh6APYJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageColorizationDataset(Dataset):\n",
        "    def __init__(self, L_data, ab_data, transform=None):\n",
        "        \"\"\"\n",
        "        Black and White (L) Images and corresponding A&B Colors dataset.\n",
        "\n",
        "        :param L_data: Grayscale images (L channel).\n",
        "        :param ab_data: Color information (A&B channels).\n",
        "        :param transform: Optional transform to be applied on samples.\n",
        "        \"\"\"\n",
        "        self.L_data = L_data\n",
        "        self.ab_data = ab_data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.L_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        L = np.array(self.L_data[idx]).reshape((224, 224, 1))\n",
        "        L = transforms.ToTensor()(L)\n",
        "\n",
        "        ab = np.array(self.ab_data[idx])\n",
        "        ab = transforms.ToTensor()(ab)\n",
        "\n",
        "        return ab, L\n",
        "\n",
        "# Batch size\n",
        "batch_size = 1\n",
        "\n",
        "# Prepare the Datasets\n",
        "train_dataset = ImageColorizationDataset(L_data=L_df, ab_data=ab_df)\n",
        "test_dataset = ImageColorizationDataset(L_data=L_df, ab_data=ab_df)\n",
        "\n",
        "# Build DataLoaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.349141Z",
          "iopub.execute_input": "2023-12-15T20:23:50.349503Z",
          "iopub.status.idle": "2023-12-15T20:23:50.360718Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.349467Z",
          "shell.execute_reply": "2023-12-15T20:23:50.359462Z"
        },
        "trusted": true,
        "id": "QWH6NJxnPYJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>IV. Data Modelling</center></h1>\n"
      ],
      "metadata": {
        "id": "-awWHwhUPYJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Generator"
      ],
      "metadata": {
        "id": "fQKq_uKePYJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.identity_map = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs.clone().detach()\n",
        "\n",
        "        out = self.relu1(self.bn1(self.conv1(x)))\n",
        "        out = self.relu2(self.bn2(self.conv2(out)))\n",
        "\n",
        "        residual = self.identity_map(x)\n",
        "        skip = out + residual\n",
        "\n",
        "        return self.relu(skip)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.362227Z",
          "iopub.execute_input": "2023-12-15T20:23:50.362535Z",
          "iopub.status.idle": "2023-12-15T20:23:50.37354Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.362498Z",
          "shell.execute_reply": "2023-12-15T20:23:50.372702Z"
        },
        "trusted": true,
        "id": "-JpAVbpuPYJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSampleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(DownSampleConv, self).__init__()\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.resblock = ResBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.resblock(self.maxpool(inputs))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.374999Z",
          "iopub.execute_input": "2023-12-15T20:23:50.375377Z",
          "iopub.status.idle": "2023-12-15T20:23:50.38816Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.375341Z",
          "shell.execute_reply": "2023-12-15T20:23:50.38726Z"
        },
        "trusted": true,
        "id": "Kn4wOuDSPYJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSampleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        self.res_block = ResBlock(in_channels + out_channels, out_channels)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.upsample(inputs)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.res_block(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.391799Z",
          "iopub.execute_input": "2023-12-15T20:23:50.392156Z",
          "iopub.status.idle": "2023-12-15T20:23:50.399503Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.392124Z",
          "shell.execute_reply": "2023-12-15T20:23:50.398688Z"
        },
        "trusted": true,
        "id": "F0-M9shOPYJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_channel, output_channel, dropout_rate = 0.2):\n",
        "        super().__init__()\n",
        "        self.encoding_layer1_ = ResBlock(input_channel,64)\n",
        "        self.encoding_layer2_ = DownSampleConv(64, 128)\n",
        "        self.encoding_layer3_ = DownSampleConv(128, 256)\n",
        "        self.bridge = DownSampleConv(256, 512)\n",
        "        self.decoding_layer3_ = UpSampleConv(512, 256)\n",
        "        self.decoding_layer2_ = UpSampleConv(256, 128)\n",
        "        self.decoding_layer1_ = UpSampleConv(128, 64)\n",
        "        self.output = nn.Conv2d(64, output_channel, kernel_size=1)\n",
        "        self.dropout = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        #Enocoder\n",
        "        e1 = self.encoding_layer1_(inputs)\n",
        "        e1 = self.dropout(e1)\n",
        "        e2 = self.encoding_layer2_(e1)\n",
        "        e2 = self.dropout(e2)\n",
        "        e3 = self.encoding_layer3_(e2)\n",
        "        e3 = self.dropout(e3)\n",
        "\n",
        "        #Bridge\n",
        "        bridge = self.bridge(e3)\n",
        "        bridge = self.dropout(bridge)\n",
        "\n",
        "        #Decoder\n",
        "        d3 = self.decoding_layer3_(bridge, e3)\n",
        "        d2 = self.decoding_layer2_(d3, e2)\n",
        "        d1 = self.decoding_layer1_(d2, e1)\n",
        "\n",
        "        #Output\n",
        "        output = self.output(d1)\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.400703Z",
          "iopub.execute_input": "2023-12-15T20:23:50.401558Z",
          "iopub.status.idle": "2023-12-15T20:23:50.413164Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.401527Z",
          "shell.execute_reply": "2023-12-15T20:23:50.412347Z"
        },
        "trusted": true,
        "id": "zHMrCpZZPYJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Generator(1,2).to(device)\n",
        "summary(model, (1, 224, 224), batch_size = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:50.414339Z",
          "iopub.execute_input": "2023-12-15T20:23:50.414615Z",
          "iopub.status.idle": "2023-12-15T20:23:58.863842Z",
          "shell.execute_reply.started": "2023-12-15T20:23:50.414589Z",
          "shell.execute_reply": "2023-12-15T20:23:58.862711Z"
        },
        "trusted": true,
        "id": "kUni4TZyPYJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator ( Critic )"
      ],
      "metadata": {
        "id": "zPL2AWbjPYJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        def critic_block(in_filters, out_filters, normalization=True):\n",
        "            \"\"\"Returns layers of each critic block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalization:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        blocks = [\n",
        "            *critic_block(in_channels, 64, normalization=False),\n",
        "            *critic_block(64, 128),\n",
        "            *critic_block(128, 256),\n",
        "            *critic_block(256, 512),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *blocks,\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, ab, l):\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        img_input = torch.cat((ab, l), 1)\n",
        "        output = self.model(img_input)\n",
        "        return output\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:58.865006Z",
          "iopub.execute_input": "2023-12-15T20:23:58.865288Z",
          "iopub.status.idle": "2023-12-15T20:23:58.875287Z",
          "shell.execute_reply.started": "2023-12-15T20:23:58.865262Z",
          "shell.execute_reply": "2023-12-15T20:23:58.874276Z"
        },
        "trusted": true,
        "id": "D-BtIM3HPYJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Critic(3).to(device)\n",
        "summary(model, [(2, 224, 224), (1, 224, 224)], batch_size = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:58.87656Z",
          "iopub.execute_input": "2023-12-15T20:23:58.876959Z",
          "iopub.status.idle": "2023-12-15T20:23:59.851843Z",
          "shell.execute_reply.started": "2023-12-15T20:23:58.876921Z",
          "shell.execute_reply": "2023-12-15T20:23:59.850745Z"
        },
        "trusted": true,
        "id": "lq_xQCBlPYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN"
      ],
      "metadata": {
        "id": "_Cp_jTgnPYJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "        if hasattr(m, 'weight'):\n",
        "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        if hasattr(m, 'bias') and m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:59.853196Z",
          "iopub.execute_input": "2023-12-15T20:23:59.853557Z",
          "iopub.status.idle": "2023-12-15T20:23:59.8608Z",
          "shell.execute_reply.started": "2023-12-15T20:23:59.853523Z",
          "shell.execute_reply": "2023-12-15T20:23:59.859433Z"
        },
        "trusted": true,
        "id": "VA3ztvb0PYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_progress(cond, real, fake, current_epoch=0, figsize=(20, 15)):\n",
        "    \"\"\"\n",
        "    Save cond, real (original), and generated (fake) images in one panel.\n",
        "    \"\"\"\n",
        "    cond = cond.detach().cpu().permute(1, 2, 0)\n",
        "    real = real.detach().cpu().permute(1, 2, 0)\n",
        "    fake = fake.detach().cpu().permute(1, 2, 0)\n",
        "\n",
        "    images = [cond, real, fake]\n",
        "    titles = ['Input', 'Real', 'Generated']\n",
        "\n",
        "    print(f'Epoch: {current_epoch}')\n",
        "    fig, ax = plt.subplots(1, 3, figsize=figsize)\n",
        "\n",
        "    for idx, (img, title) in enumerate(zip(images, titles)):\n",
        "        if idx == 0:\n",
        "            ab = torch.zeros((224, 224, 2))\n",
        "            img = torch.cat([images[0] * 100, ab], dim=2).numpy()\n",
        "            imgan = lab2rgb(img)\n",
        "        else:\n",
        "            imgan = lab_to_rgb(images[0], img)\n",
        "\n",
        "        ax[idx].imshow(imgan)\n",
        "        ax[idx].axis(\"off\")\n",
        "        ax[idx].set_title('{}'.format(title))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:59.862239Z",
          "iopub.execute_input": "2023-12-15T20:23:59.8626Z",
          "iopub.status.idle": "2023-12-15T20:23:59.874112Z",
          "shell.execute_reply.started": "2023-12-15T20:23:59.86256Z",
          "shell.execute_reply": "2023-12-15T20:23:59.873167Z"
        },
        "trusted": true,
        "id": "9gc3Hu-ePYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CWGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, learning_rate=0.0002, lambda_recon=100, display_step=10, lambda_gp=10, lambda_r1=10,):\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.display_step = display_step\n",
        "\n",
        "        self.generator = Generator(in_channels, out_channels)\n",
        "        self.critic = Critic(in_channels + out_channels)\n",
        "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
        "        self.optimizer_C = optim.Adam(self.critic.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
        "        self.lambda_recon = lambda_recon\n",
        "        self.lambda_gp = lambda_gp\n",
        "        self.lambda_r1 = lambda_r1\n",
        "        self.recon_criterion = nn.L1Loss()\n",
        "        self.generator_losses, self.critic_losses  =[],[]\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return [self.optimizer_C, self.optimizer_G]\n",
        "\n",
        "    def generator_step(self, real_images, conditioned_images):\n",
        "        # WGAN has only a reconstruction loss\n",
        "        self.optimizer_G.zero_grad()\n",
        "        fake_images = self.generator(conditioned_images)\n",
        "        recon_loss = self.recon_criterion(fake_images, real_images)\n",
        "        recon_loss.backward()\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "        # Keep track of the average generator loss\n",
        "        self.generator_losses += [recon_loss.item()]\n",
        "\n",
        "\n",
        "    def critic_step(self, real_images, conditioned_images):\n",
        "        self.optimizer_C.zero_grad()\n",
        "        fake_images = self.generator(conditioned_images)\n",
        "        fake_logits = self.critic(fake_images, conditioned_images)\n",
        "        real_logits = self.critic(real_images, conditioned_images)\n",
        "\n",
        "        # Compute the loss for the critic\n",
        "        loss_C = real_logits.mean() - fake_logits.mean()\n",
        "\n",
        "        # Compute the gradient penalty\n",
        "        alpha = torch.rand(real_images.size(0), 1, 1, 1, requires_grad=True)\n",
        "        alpha = alpha.to(device)\n",
        "        interpolated = (alpha * real_images + (1 - alpha) * fake_images.detach()).requires_grad_(True)\n",
        "\n",
        "        interpolated_logits = self.critic(interpolated, conditioned_images)\n",
        "\n",
        "        grad_outputs = torch.ones_like(interpolated_logits, dtype=torch.float32, requires_grad=True)\n",
        "        gradients = torch.autograd.grad(outputs=interpolated_logits, inputs=interpolated, grad_outputs=grad_outputs,create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "\n",
        "        gradients = gradients.view(len(gradients), -1)\n",
        "        gradients_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        loss_C += self.lambda_gp * gradients_penalty\n",
        "\n",
        "        # Compute the R1 regularization loss\n",
        "        r1_reg = gradients.pow(2).sum(1).mean()\n",
        "        loss_C += self.lambda_r1 * r1_reg\n",
        "\n",
        "        # Backpropagation\n",
        "        loss_C.backward()\n",
        "        self.optimizer_C.step()\n",
        "        self.critic_losses += [loss_C.item()]\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, condition = batch\n",
        "        if optimizer_idx == 0:\n",
        "            self.critic_step(real, condition)\n",
        "        elif optimizer_idx == 1:\n",
        "            self.generator_step(real, condition)\n",
        "        gen_mean = sum(self.generator_losses[-self.display_step:]) / self.display_step\n",
        "        crit_mean = sum(self.critic_losses[-self.display_step:]) / self.display_step\n",
        "        if self.current_epoch%self.display_step==0 and batch_idx==0 and optimizer_idx==1:\n",
        "            fake = self.generator(condition).detach()\n",
        "            torch.save(cwgan.generator.state_dict(), \"ResUnet_\"+ str(self.current_epoch) +\".pt\")\n",
        "            torch.save(cwgan.critic.state_dict(), \"PatchGAN_\"+ str(self.current_epoch) +\".pt\")\n",
        "            print(f\"Epoch {self.current_epoch} : Generator loss: {gen_mean}, Critic loss: {crit_mean}\")\n",
        "            display_progress(condition[0], real[0], fake[0], self.current_epoch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:59.875757Z",
          "iopub.execute_input": "2023-12-15T20:23:59.876143Z",
          "iopub.status.idle": "2023-12-15T20:23:59.903523Z",
          "shell.execute_reply.started": "2023-12-15T20:23:59.87611Z",
          "shell.execute_reply": "2023-12-15T20:23:59.902337Z"
        },
        "trusted": true,
        "id": "z8MGzBUxPYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "cwgan = CWGAN(in_channels = 1, out_channels = 2 ,learning_rate=2e-4, lambda_recon=100, display_step=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:23:59.905099Z",
          "iopub.execute_input": "2023-12-15T20:23:59.905447Z",
          "iopub.status.idle": "2023-12-15T20:24:00.223724Z",
          "shell.execute_reply.started": "2023-12-15T20:23:59.905416Z",
          "shell.execute_reply": "2023-12-15T20:24:00.222836Z"
        },
        "trusted": true,
        "id": "wpOg62toPYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(max_epochs=500, gpus=-1)\n",
        "trainer.fit(cwgan, train_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T20:24:00.225013Z",
          "iopub.execute_input": "2023-12-15T20:24:00.22534Z"
        },
        "trusted": true,
        "id": "DGXJBmZaPYJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>VI. Model Inferencing</center></h1>\n"
      ],
      "metadata": {
        "id": "IagSyVpcPYJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30, 60))\n",
        "idx = 1\n",
        "\n",
        "for batch_idx, batch in enumerate(test_loader):\n",
        "    real, condition = batch\n",
        "\n",
        "    # Move data to the same device as the model\n",
        "    real = real.to(device)\n",
        "    condition = condition.to(device)\n",
        "\n",
        "    # Forward pass through the generator\n",
        "    pred = cwgan.generator(condition).detach().squeeze().permute(1, 2, 0)\n",
        "\n",
        "    # Move data back to CPU for visualization if needed\n",
        "    condition = condition.cpu().detach().squeeze(0).permute(1, 2, 0)\n",
        "    real = real.cpu().detach().squeeze(0).permute(1, 2, 0)\n",
        "\n",
        "    # Increase spacing between each picture\n",
        "    plt.subplots_adjust(wspace=0, hspace=0.5)\n",
        "\n",
        "    plt.subplot(6, 3, idx)\n",
        "    plt.grid(False)\n",
        "\n",
        "    ab = torch.zeros((224, 224, 2))\n",
        "    img = torch.cat([condition * 100, ab], dim=2).numpy()\n",
        "    imgan = lab2rgb(img)\n",
        "    plt.imshow(imgan)\n",
        "    plt.title('Input')\n",
        "\n",
        "    plt.subplot(6, 3, idx + 1)\n",
        "    ab = torch.zeros((224, 224, 2))\n",
        "    imgan = lab_to_rgb(condition, real)\n",
        "    plt.imshow(imgan)\n",
        "    plt.title('Real')\n",
        "\n",
        "    plt.subplot(6, 3, idx + 2)\n",
        "    imgan = lab_to_rgb(condition, pred)\n",
        "    plt.title('Generated')\n",
        "    plt.imshow(imgan)\n",
        "\n",
        "    idx += 3\n",
        "\n",
        "    if idx >= 18:\n",
        "        break\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KU8kqta-PYJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><center>VI. Evaluation</center></h1>\n"
      ],
      "metadata": {
        "id": "MtNNSC-pPYJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception Score"
      ],
      "metadata": {
        "id": "Pinu4rO3PYJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    cwgan.generator.eval()\n",
        "    all_preds = []\n",
        "    all_real = []\n",
        "\n",
        "    for batch_idx, (real, condition) in enumerate(test_loader):\n",
        "        condition = condition.to(device)  # Move condition to the same device as the model\n",
        "        pred = cwgan.generator(condition).detach()\n",
        "        Lab = torch.cat([condition, pred], dim=1).cpu().numpy()  # Move to CPU before converting to numpy\n",
        "        Lab_real = torch.cat([condition.cpu(), real.to(device).cpu()], dim=1).numpy()\n",
        "        all_preds.append(Lab.squeeze())\n",
        "        all_real.append(Lab_real.squeeze())\n",
        "\n",
        "        if batch_idx == 500:\n",
        "            break\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WXatAzlDPYJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionScore:\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.inception = self._initialize_inception()\n",
        "        self.inception.eval()\n",
        "\n",
        "    def _initialize_inception(self):\n",
        "        inception = inception_v3(pretrained=True, transform_input=False).to(self.device)\n",
        "        return inception\n",
        "\n",
        "    def calculate_is(self, generated_images):\n",
        "        generated_images = generated_images.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated_features = self.inception(generated_images.view(-1, 3, 224, 224))\n",
        "\n",
        "        generated_features = generated_features.view(generated_features.size(0), -1)\n",
        "        p = F.softmax(generated_features, dim=1)\n",
        "\n",
        "        kl = p * (torch.log(p) - torch.log(torch.tensor(1.0 / generated_features.size(1)).to(self.device)))\n",
        "        kl = kl.sum(dim=1)\n",
        "\n",
        "        return kl.mean().item(), kl.std().item()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lFyT7MY-PYJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming all_preds and all_real are already PyTorch tensors\n",
        "device = \"cuda\"  # or \"cpu\" if you don't have a GPU\n",
        "is_calculator = InceptionScore(device)\n",
        "\n",
        "# Ensure all_preds and all_real are PyTorch tensors\n",
        "all_preds = torch.tensor(all_preds).float().to(device)\n",
        "all_real = torch.tensor(all_real).float().to(device)\n",
        "\n",
        "# Move tensors to CPU before converting to NumPy arrays\n",
        "all_preds_cpu = all_preds.cpu().numpy()\n",
        "all_real_cpu = all_real.cpu().numpy()\n",
        "\n",
        "is_model = InceptionScore(device)\n",
        "\n",
        "# Calculate the Inception Score\n",
        "mean_real, std_real = is_model.calculate_is(all_real)\n",
        "print(\"Inception Score of real images: mean: {:.4f}, std: {:.4f}\".format(mean_real, std_real))\n",
        "mean_is, std_is = is_model.calculate_is(all_preds)\n",
        "print(\"Inception Score of fake images: mean: {:.4f}, std: {:.4f}\".format(mean_is, std_is))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "x7MKkKSgPYJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implemenation of Fréchet Inception Distance (FID)"
      ],
      "metadata": {
        "id": "dOjl8k3jPYJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FID:\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.inception = inception_v3(pretrained=True, transform_input=False).to(self.device)\n",
        "        self.inception.eval()\n",
        "        self.mu = None\n",
        "        self.sigma = None\n",
        "\n",
        "    def preprocess_images(self, images):\n",
        "        return images.view(-1, 3, 224, 224).to(self.device)\n",
        "\n",
        "    def calculate_fid(self, real_images, generated_images):\n",
        "        real_images, generated_images = self.preprocess_images(real_images), self.preprocess_images(generated_images)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            real_features, generated_features = self.inception(real_images), self.inception(generated_images)\n",
        "\n",
        "        real_features, generated_features = real_features.view(real_features.size(0), -1), generated_features.view(generated_features.size(0), -1)\n",
        "\n",
        "        if self.mu is None:\n",
        "            self.mu, self.sigma = real_features.mean(dim=0), real_features.std(dim=0)\n",
        "\n",
        "        real_mu, real_sigma = real_features.mean(dim=0), real_features.std(dim=0)\n",
        "        generated_mu, generated_sigma = generated_features.mean(dim=0), generated_features.std(dim=0)\n",
        "\n",
        "        mu_diff, sigma_diff = real_mu - generated_mu, real_sigma - generated_sigma\n",
        "\n",
        "        fid = mu_diff.pow(2).sum() + sigma_diff.pow(2).sum() + (self.sigma - generated_sigma).pow(2).sum()\n",
        "        return fid.item()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5nTlVsclPYJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the FID class\n",
        "fid_calculator = FID(device)\n",
        "\n",
        "# Calculate the FID\n",
        "fid_value = fid_calculator.calculate_fid(all_real, all_preds)\n",
        "print(f\"FID: {fid_value:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7J3osfvCPYJu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}